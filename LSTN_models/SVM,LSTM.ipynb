{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from pandas import concat\n",
    "from datetime import datetime\n",
    "from sklearn.svm import SVR\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "from keras import regularizers\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     pm2.5  dew_point  air_temp  air_pressure  wind_speed  \\\n",
      "date_1                                                                      \n",
      "2010-01-02 00:00:00  129.0        -16      -4.0        1020.0        1.79   \n",
      "2010-01-02 01:00:00  148.0        -15      -4.0        1020.0        2.68   \n",
      "2010-01-02 02:00:00  159.0        -11      -5.0        1021.0        3.57   \n",
      "2010-01-02 03:00:00  181.0         -7      -5.0        1022.0        5.36   \n",
      "2010-01-02 04:00:00  138.0         -7      -5.0        1022.0        6.25   \n",
      "\n",
      "                     cumulative_snow_hours  cumulative_rain_hours  \n",
      "date_1                                                             \n",
      "2010-01-02 00:00:00                    0.0                    0.0  \n",
      "2010-01-02 01:00:00                    0.0                    0.0  \n",
      "2010-01-02 02:00:00                    0.0                    0.0  \n",
      "2010-01-02 03:00:00                    1.0                    0.0  \n",
      "2010-01-02 04:00:00                    2.0                    0.0  \n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "def parse(x):\n",
    "    return datetime.strptime(x, '%Y %m %d %H')\n",
    "dataset = pd.read_csv('merged_final_v2.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
    "dataset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# manually specify column names\n",
    "dataset.index.name = 'date_1'\n",
    "# drop the first 24 hours\n",
    "dataset = dataset[24:]\n",
    "new_dataset = dataset[['pm2.5','dew_point','air_temp','air_pressure','wind_dir','wind_speed','cumulative_snow_hours','cumulative_rain_hours']]\n",
    "#drop column wind_dir\n",
    "new_dataset = new_dataset.drop('wind_dir', 1)\n",
    "# summarize first 5 rows\n",
    "print(new_dataset.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pm2.5                    0\n",
       "dew_point                0\n",
       "air_temp                 0\n",
       "air_pressure             0\n",
       "wind_speed               0\n",
       "cumulative_snow_hours    0\n",
       "cumulative_rain_hours    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.129779   0.031431   0.015356   0.003061   0.000179   0.000000   \n",
      "2   0.148893   0.031528   0.015356   0.003061   0.000268   0.000000   \n",
      "3   0.159960   0.031915   0.015257   0.003167   0.000357   0.000000   \n",
      "4   0.182093   0.032302   0.015257   0.003272   0.000536   0.010101   \n",
      "5   0.138833   0.032302   0.015257   0.003272   0.000625   0.020202   \n",
      "\n",
      "   var7(t-1)   var1(t)   var2(t)   var3(t)   var4(t)   var5(t)   var6(t)  \\\n",
      "1        0.0  0.148893  0.031528  0.015356  0.003061  0.000268  0.000000   \n",
      "2        0.0  0.159960  0.031915  0.015257  0.003167  0.000357  0.000000   \n",
      "3        0.0  0.182093  0.032302  0.015257  0.003272  0.000536  0.010101   \n",
      "4        0.0  0.138833  0.032302  0.015257  0.003272  0.000625  0.020202   \n",
      "5        0.0  0.109658  0.032302  0.015159  0.003272  0.000714  0.030303   \n",
      "\n",
      "   var7(t)  \n",
      "1      0.0  \n",
      "2      0.0  \n",
      "3      0.0  \n",
      "4      0.0  \n",
      "5      0.0  \n",
      "(43800, 13) (43800,) (25145, 13) (25145,)\n"
     ]
    }
   ],
   "source": [
    " def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "values = new_dataset.values\n",
    "\n",
    "\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "print(reframed.head())\n",
    "values = reframed.values\n",
    "\n",
    "n_train_hours = 1825 * 24\n",
    "\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "train_X, train_y = train[:, 1:], train[:, 1:]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = df.temp.values\n",
    "# X = df.iloc[:, 1:].values\n",
    "\n",
    "# # Train on 70% of the data\n",
    "# train_idx = int(len(df) * .7)\n",
    "\n",
    "# # create train and test data\n",
    "# X_train, y_train, X_test, y_test = X[:train_idx], y[:train_idx], X[train_idx:], y[:train_idx]\n",
    "\n",
    "# # fit and predict\n",
    "# clf = SVR()\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.114\n"
     ]
    }
   ],
   "source": [
    "clf = SVR()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "y_pred = clf.predict(test_X)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_pred, test_y))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68943, 28)\n",
      "       var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var6(t-3)  \\\n",
      "3       0.129779   0.031431   0.015356   0.003061   0.000179   0.000000   \n",
      "4       0.148893   0.031528   0.015356   0.003061   0.000268   0.000000   \n",
      "5       0.159960   0.031915   0.015257   0.003167   0.000357   0.000000   \n",
      "6       0.182093   0.032302   0.015257   0.003272   0.000536   0.010101   \n",
      "7       0.138833   0.032302   0.015257   0.003272   0.000625   0.020202   \n",
      "8       0.109658   0.032302   0.015159   0.003272   0.000714   0.030303   \n",
      "9       0.105634   0.032302   0.015159   0.003378   0.000893   0.040404   \n",
      "10      0.124748   0.032302   0.015257   0.003483   0.001072   0.000000   \n",
      "11      0.120724   0.032205   0.015159   0.003483   0.001251   0.000000   \n",
      "12      0.132797   0.032302   0.015257   0.003589   0.001430   0.000000   \n",
      "13      0.140845   0.032302   0.015257   0.003694   0.001743   0.010101   \n",
      "14      0.152918   0.032205   0.015257   0.003694   0.002056   0.000000   \n",
      "15      0.148893   0.032205   0.015257   0.003694   0.002369   0.000000   \n",
      "16      0.164990   0.032205   0.015257   0.003589   0.002771   0.000000   \n",
      "17      0.158954   0.032108   0.015257   0.003589   0.003173   0.000000   \n",
      "18      0.154930   0.032108   0.015257   0.003589   0.003575   0.000000   \n",
      "19      0.159960   0.032108   0.015257   0.003694   0.003754   0.000000   \n",
      "20      0.164990   0.032205   0.015257   0.003800   0.003933   0.000000   \n",
      "21      0.171026   0.032205   0.015257   0.003800   0.004246   0.000000   \n",
      "22      0.149899   0.032205   0.015257   0.003905   0.004425   0.000000   \n",
      "23      0.154930   0.032302   0.015257   0.003905   0.004604   0.000000   \n",
      "24      0.164990   0.032302   0.015257   0.003800   0.004917   0.010101   \n",
      "25      0.156942   0.032205   0.015159   0.003905   0.005231   0.020202   \n",
      "26      0.126761   0.032205   0.015159   0.003800   0.005544   0.030303   \n",
      "27      0.090543   0.032302   0.015159   0.003800   0.005857   0.040404   \n",
      "28      0.063380   0.032205   0.015159   0.003694   0.006170   0.050505   \n",
      "29      0.065392   0.032205   0.015061   0.003694   0.006572   0.060606   \n",
      "30      0.055332   0.032205   0.015061   0.003589   0.006885   0.070707   \n",
      "31      0.065392   0.032205   0.015061   0.003483   0.007287   0.080808   \n",
      "32      0.083501   0.032108   0.014962   0.003483   0.007689   0.090909   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "68916   0.074318   0.026209   0.012797   0.968355   0.001000   0.007673   \n",
      "68917   0.074318   0.026209   0.013781   0.968355   0.001000   0.007673   \n",
      "68918   0.074318   0.026015   0.015257   0.972768   0.000000   0.007673   \n",
      "68919   0.074318   0.026209   0.012797   0.968355   0.002000   0.007673   \n",
      "68920   0.074318   0.026209   0.014765   0.968355   0.002000   0.007673   \n",
      "68921   0.074318   0.026112   0.014273   0.972873   0.001000   0.007673   \n",
      "68922   0.074318   0.026209   0.012797   0.968355   0.003000   0.007673   \n",
      "68923   0.074318   0.026209   0.014765   0.968355   0.004000   0.007673   \n",
      "68924   0.074318   0.023598   0.018899   0.972768   0.002000   0.007673   \n",
      "68925   0.074318   0.025242   0.015750   0.968355   0.005001   0.007673   \n",
      "68926   0.074318   0.022340   0.018703   0.968355   0.006001   0.343434   \n",
      "68927   0.074318   0.018472   0.020671   0.977201   0.006001   0.007673   \n",
      "68928   0.074318   0.018472   0.020671   0.968355   0.010001   0.007673   \n",
      "68929   0.074318   0.016538   0.020671   0.968355   0.011001   0.007673   \n",
      "68930   0.074318   0.018279   0.019785   0.980578   0.007001   0.007673   \n",
      "68931   0.074318   0.015571   0.021656   0.968355   0.011001   0.007673   \n",
      "68932   0.074318   0.014603   0.020671   0.968355   0.009001   0.007673   \n",
      "68933   0.074318   0.015087   0.020179   0.981317   0.004000   0.007673   \n",
      "68934   0.074318   0.014603   0.021656   0.968355   0.009001   0.007673   \n",
      "68935   0.074318   0.011702   0.020671   0.968355   0.009001   0.007673   \n",
      "68936   0.074318   0.011315   0.019195   0.983745   0.003000   0.007673   \n",
      "68937   0.074318   0.011702   0.017718   0.968355   0.009001   0.007673   \n",
      "68938   0.074318   0.010735   0.016734   0.968355   0.010001   0.007673   \n",
      "68939   0.074318   0.008897   0.016242   0.987545   0.004000   0.007673   \n",
      "68940   0.074318   0.011702   0.014765   0.968355   0.008001   0.007673   \n",
      "68941   0.074318   0.011702   0.013781   0.968355   0.009001   0.007673   \n",
      "68942   0.074318   0.009574   0.014273   0.990500   0.002000   0.007673   \n",
      "68943   0.074318   0.011702   0.013781   0.968355   0.010001   0.757576   \n",
      "68944   0.074318   0.011702   0.013781   0.968355   0.011001   0.858586   \n",
      "68945   0.074318   0.010542   0.013092   0.990078   0.004000   0.007673   \n",
      "\n",
      "       var7(t-3)  var1(t-2)  var2(t-2)  var3(t-2)    ...     var5(t-1)  \\\n",
      "3       0.000000   0.148893   0.031528   0.015356    ...      0.000357   \n",
      "4       0.000000   0.159960   0.031915   0.015257    ...      0.000536   \n",
      "5       0.000000   0.182093   0.032302   0.015257    ...      0.000625   \n",
      "6       0.000000   0.138833   0.032302   0.015257    ...      0.000714   \n",
      "7       0.000000   0.109658   0.032302   0.015159    ...      0.000893   \n",
      "8       0.000000   0.105634   0.032302   0.015159    ...      0.001072   \n",
      "9       0.000000   0.124748   0.032302   0.015257    ...      0.001251   \n",
      "10      0.000000   0.120724   0.032205   0.015159    ...      0.001430   \n",
      "11      0.000000   0.132797   0.032302   0.015257    ...      0.001743   \n",
      "12      0.000000   0.140845   0.032302   0.015257    ...      0.002056   \n",
      "13      0.000000   0.152918   0.032205   0.015257    ...      0.002369   \n",
      "14      0.000000   0.148893   0.032205   0.015257    ...      0.002771   \n",
      "15      0.000000   0.164990   0.032205   0.015257    ...      0.003173   \n",
      "16      0.000000   0.158954   0.032108   0.015257    ...      0.003575   \n",
      "17      0.000000   0.154930   0.032108   0.015257    ...      0.003754   \n",
      "18      0.000000   0.159960   0.032108   0.015257    ...      0.003933   \n",
      "19      0.000000   0.164990   0.032205   0.015257    ...      0.004246   \n",
      "20      0.000000   0.171026   0.032205   0.015257    ...      0.004425   \n",
      "21      0.000000   0.149899   0.032205   0.015257    ...      0.004604   \n",
      "22      0.000000   0.154930   0.032302   0.015257    ...      0.004917   \n",
      "23      0.000000   0.164990   0.032302   0.015257    ...      0.005231   \n",
      "24      0.000000   0.156942   0.032205   0.015159    ...      0.005544   \n",
      "25      0.000000   0.126761   0.032205   0.015159    ...      0.005857   \n",
      "26      0.000000   0.090543   0.032302   0.015159    ...      0.006170   \n",
      "27      0.000000   0.063380   0.032205   0.015159    ...      0.006572   \n",
      "28      0.000000   0.065392   0.032205   0.015061    ...      0.006885   \n",
      "29      0.000000   0.055332   0.032205   0.015061    ...      0.007287   \n",
      "30      0.000000   0.065392   0.032205   0.015061    ...      0.007689   \n",
      "31      0.000000   0.083501   0.032108   0.014962    ...      0.008091   \n",
      "32      0.000000   0.091549   0.032012   0.014962    ...      0.008493   \n",
      "...          ...        ...        ...        ...    ...           ...   \n",
      "68916   0.123457   0.074318   0.026209   0.013781    ...      0.000000   \n",
      "68917   0.123457   0.074318   0.026015   0.015257    ...      0.002000   \n",
      "68918   0.074074   0.074318   0.026209   0.012797    ...      0.002000   \n",
      "68919   0.123457   0.074318   0.026209   0.014765    ...      0.001000   \n",
      "68920   0.123457   0.074318   0.026112   0.014273    ...      0.003000   \n",
      "68921   0.074074   0.074318   0.026209   0.012797    ...      0.004000   \n",
      "68922   0.123457   0.074318   0.026209   0.014765    ...      0.002000   \n",
      "68923   0.123457   0.074318   0.023598   0.018899    ...      0.005001   \n",
      "68924   0.074074   0.074318   0.025242   0.015750    ...      0.006001   \n",
      "68925   0.123457   0.074318   0.022340   0.018703    ...      0.006001   \n",
      "68926   0.123457   0.074318   0.018472   0.020671    ...      0.010001   \n",
      "68927   0.074074   0.074318   0.018472   0.020671    ...      0.011001   \n",
      "68928   0.123457   0.074318   0.016538   0.020671    ...      0.007001   \n",
      "68929   0.123457   0.074318   0.018279   0.019785    ...      0.011001   \n",
      "68930   0.074074   0.074318   0.015571   0.021656    ...      0.009001   \n",
      "68931   0.123457   0.074318   0.014603   0.020671    ...      0.004000   \n",
      "68932   0.123457   0.074318   0.015087   0.020179    ...      0.009001   \n",
      "68933   0.074074   0.074318   0.014603   0.021656    ...      0.009001   \n",
      "68934   0.123457   0.074318   0.011702   0.020671    ...      0.003000   \n",
      "68935   0.123457   0.074318   0.011315   0.019195    ...      0.009001   \n",
      "68936   0.074074   0.074318   0.011702   0.017718    ...      0.010001   \n",
      "68937   0.123457   0.074318   0.010735   0.016734    ...      0.004000   \n",
      "68938   0.123457   0.074318   0.008897   0.016242    ...      0.008001   \n",
      "68939   0.074074   0.074318   0.011702   0.014765    ...      0.009001   \n",
      "68940   0.123457   0.074318   0.011702   0.013781    ...      0.002000   \n",
      "68941   0.123457   0.074318   0.009574   0.014273    ...      0.010001   \n",
      "68942   0.074074   0.074318   0.011702   0.013781    ...      0.011001   \n",
      "68943   0.123457   0.074318   0.011702   0.013781    ...      0.004000   \n",
      "68944   0.123457   0.074318   0.010542   0.013092    ...      0.005001   \n",
      "68945   0.074074   0.074318   0.012669   0.012797    ...      0.008001   \n",
      "\n",
      "       var6(t-1)  var7(t-1)   var1(t)   var2(t)   var3(t)   var4(t)   var5(t)  \\\n",
      "3       0.000000   0.000000  0.182093  0.032302  0.015257  0.003272  0.000536   \n",
      "4       0.010101   0.000000  0.138833  0.032302  0.015257  0.003272  0.000625   \n",
      "5       0.020202   0.000000  0.109658  0.032302  0.015159  0.003272  0.000714   \n",
      "6       0.030303   0.000000  0.105634  0.032302  0.015159  0.003378  0.000893   \n",
      "7       0.040404   0.000000  0.124748  0.032302  0.015257  0.003483  0.001072   \n",
      "8       0.000000   0.000000  0.120724  0.032205  0.015159  0.003483  0.001251   \n",
      "9       0.000000   0.000000  0.132797  0.032302  0.015257  0.003589  0.001430   \n",
      "10      0.000000   0.000000  0.140845  0.032302  0.015257  0.003694  0.001743   \n",
      "11      0.010101   0.000000  0.152918  0.032205  0.015257  0.003694  0.002056   \n",
      "12      0.000000   0.000000  0.148893  0.032205  0.015257  0.003694  0.002369   \n",
      "13      0.000000   0.000000  0.164990  0.032205  0.015257  0.003589  0.002771   \n",
      "14      0.000000   0.000000  0.158954  0.032108  0.015257  0.003589  0.003173   \n",
      "15      0.000000   0.000000  0.154930  0.032108  0.015257  0.003589  0.003575   \n",
      "16      0.000000   0.000000  0.159960  0.032108  0.015257  0.003694  0.003754   \n",
      "17      0.000000   0.000000  0.164990  0.032205  0.015257  0.003800  0.003933   \n",
      "18      0.000000   0.000000  0.171026  0.032205  0.015257  0.003800  0.004246   \n",
      "19      0.000000   0.000000  0.149899  0.032205  0.015257  0.003905  0.004425   \n",
      "20      0.000000   0.000000  0.154930  0.032302  0.015257  0.003905  0.004604   \n",
      "21      0.000000   0.000000  0.164990  0.032302  0.015257  0.003800  0.004917   \n",
      "22      0.010101   0.000000  0.156942  0.032205  0.015159  0.003905  0.005231   \n",
      "23      0.020202   0.000000  0.126761  0.032205  0.015159  0.003800  0.005544   \n",
      "24      0.030303   0.000000  0.090543  0.032302  0.015159  0.003800  0.005857   \n",
      "25      0.040404   0.000000  0.063380  0.032205  0.015159  0.003694  0.006170   \n",
      "26      0.050505   0.000000  0.065392  0.032205  0.015061  0.003694  0.006572   \n",
      "27      0.060606   0.000000  0.055332  0.032205  0.015061  0.003589  0.006885   \n",
      "28      0.070707   0.000000  0.065392  0.032205  0.015061  0.003483  0.007287   \n",
      "29      0.080808   0.000000  0.083501  0.032108  0.014962  0.003483  0.007689   \n",
      "30      0.090909   0.000000  0.091549  0.032012  0.014962  0.003483  0.008091   \n",
      "31      0.101010   0.000000  0.086519  0.032012  0.014864  0.003483  0.008493   \n",
      "32      0.111111   0.000000  0.082495  0.032012  0.014864  0.003483  0.008985   \n",
      "...          ...        ...       ...       ...       ...       ...       ...   \n",
      "68916   0.007673   0.074074  0.074318  0.026209  0.012797  0.968355  0.002000   \n",
      "68917   0.007673   0.123457  0.074318  0.026209  0.014765  0.968355  0.002000   \n",
      "68918   0.007673   0.123457  0.074318  0.026112  0.014273  0.972873  0.001000   \n",
      "68919   0.007673   0.074074  0.074318  0.026209  0.012797  0.968355  0.003000   \n",
      "68920   0.007673   0.123457  0.074318  0.026209  0.014765  0.968355  0.004000   \n",
      "68921   0.007673   0.123457  0.074318  0.023598  0.018899  0.972768  0.002000   \n",
      "68922   0.007673   0.074074  0.074318  0.025242  0.015750  0.968355  0.005001   \n",
      "68923   0.007673   0.123457  0.074318  0.022340  0.018703  0.968355  0.006001   \n",
      "68924   0.343434   0.123457  0.074318  0.018472  0.020671  0.977201  0.006001   \n",
      "68925   0.007673   0.074074  0.074318  0.018472  0.020671  0.968355  0.010001   \n",
      "68926   0.007673   0.123457  0.074318  0.016538  0.020671  0.968355  0.011001   \n",
      "68927   0.007673   0.123457  0.074318  0.018279  0.019785  0.980578  0.007001   \n",
      "68928   0.007673   0.074074  0.074318  0.015571  0.021656  0.968355  0.011001   \n",
      "68929   0.007673   0.123457  0.074318  0.014603  0.020671  0.968355  0.009001   \n",
      "68930   0.007673   0.123457  0.074318  0.015087  0.020179  0.981317  0.004000   \n",
      "68931   0.007673   0.074074  0.074318  0.014603  0.021656  0.968355  0.009001   \n",
      "68932   0.007673   0.123457  0.074318  0.011702  0.020671  0.968355  0.009001   \n",
      "68933   0.007673   0.123457  0.074318  0.011315  0.019195  0.983745  0.003000   \n",
      "68934   0.007673   0.074074  0.074318  0.011702  0.017718  0.968355  0.009001   \n",
      "68935   0.007673   0.123457  0.074318  0.010735  0.016734  0.968355  0.010001   \n",
      "68936   0.007673   0.123457  0.074318  0.008897  0.016242  0.987545  0.004000   \n",
      "68937   0.007673   0.074074  0.074318  0.011702  0.014765  0.968355  0.008001   \n",
      "68938   0.007673   0.123457  0.074318  0.011702  0.013781  0.968355  0.009001   \n",
      "68939   0.007673   0.123457  0.074318  0.009574  0.014273  0.990500  0.002000   \n",
      "68940   0.007673   0.074074  0.074318  0.011702  0.013781  0.968355  0.010001   \n",
      "68941   0.757576   0.123457  0.074318  0.011702  0.013781  0.968355  0.011001   \n",
      "68942   0.858586   0.123457  0.074318  0.010542  0.013092  0.990078  0.004000   \n",
      "68943   0.007673   0.074074  0.074318  0.012669  0.012797  0.968355  0.005001   \n",
      "68944   0.007673   0.123457  0.074318  0.013636  0.012797  0.968355  0.008001   \n",
      "68945   0.007673   0.123457  0.074318  0.010445  0.012895  0.989550  0.002000   \n",
      "\n",
      "        var6(t)   var7(t)  \n",
      "3      0.010101  0.000000  \n",
      "4      0.020202  0.000000  \n",
      "5      0.030303  0.000000  \n",
      "6      0.040404  0.000000  \n",
      "7      0.000000  0.000000  \n",
      "8      0.000000  0.000000  \n",
      "9      0.000000  0.000000  \n",
      "10     0.010101  0.000000  \n",
      "11     0.000000  0.000000  \n",
      "12     0.000000  0.000000  \n",
      "13     0.000000  0.000000  \n",
      "14     0.000000  0.000000  \n",
      "15     0.000000  0.000000  \n",
      "16     0.000000  0.000000  \n",
      "17     0.000000  0.000000  \n",
      "18     0.000000  0.000000  \n",
      "19     0.000000  0.000000  \n",
      "20     0.000000  0.000000  \n",
      "21     0.010101  0.000000  \n",
      "22     0.020202  0.000000  \n",
      "23     0.030303  0.000000  \n",
      "24     0.040404  0.000000  \n",
      "25     0.050505  0.000000  \n",
      "26     0.060606  0.000000  \n",
      "27     0.070707  0.000000  \n",
      "28     0.080808  0.000000  \n",
      "29     0.090909  0.000000  \n",
      "30     0.101010  0.000000  \n",
      "31     0.111111  0.000000  \n",
      "32     0.121212  0.000000  \n",
      "...         ...       ...  \n",
      "68916  0.007673  0.123457  \n",
      "68917  0.007673  0.123457  \n",
      "68918  0.007673  0.074074  \n",
      "68919  0.007673  0.123457  \n",
      "68920  0.007673  0.123457  \n",
      "68921  0.007673  0.074074  \n",
      "68922  0.007673  0.123457  \n",
      "68923  0.343434  0.123457  \n",
      "68924  0.007673  0.074074  \n",
      "68925  0.007673  0.123457  \n",
      "68926  0.007673  0.123457  \n",
      "68927  0.007673  0.074074  \n",
      "68928  0.007673  0.123457  \n",
      "68929  0.007673  0.123457  \n",
      "68930  0.007673  0.074074  \n",
      "68931  0.007673  0.123457  \n",
      "68932  0.007673  0.123457  \n",
      "68933  0.007673  0.074074  \n",
      "68934  0.007673  0.123457  \n",
      "68935  0.007673  0.123457  \n",
      "68936  0.007673  0.074074  \n",
      "68937  0.007673  0.123457  \n",
      "68938  0.007673  0.123457  \n",
      "68939  0.007673  0.074074  \n",
      "68940  0.757576  0.123457  \n",
      "68941  0.858586  0.123457  \n",
      "68942  0.007673  0.074074  \n",
      "68943  0.007673  0.123457  \n",
      "68944  0.007673  0.123457  \n",
      "68945  0.007673  0.074074  \n",
      "\n",
      "[68943 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "values = new_dataset.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# specify the number of lag hours\n",
    "n_hours = 3\n",
    "n_features = 7\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)\n",
    "print(reframed.shape)\n",
    " \n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "print(reframed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43800, 21) 43800 (43800,)\n",
      "(43800, 21) (43800,) (25143, 21) (25143,)\n"
     ]
    }
   ],
   "source": [
    "n_train_hours = 1825 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "# train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "# test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.085\n"
     ]
    }
   ],
   "source": [
    "clf = SVR()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "y_pred = clf.predict(test_X)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(test_y, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -7:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -7:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
